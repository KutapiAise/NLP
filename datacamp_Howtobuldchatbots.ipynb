{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "datacamp:Howtobuldchatbots.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KutapiAise/NLP/blob/master/datacamp_Howtobuldchatbots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfWOMfxPii21",
        "colab_type": "text"
      },
      "source": [
        "#### Introduction to conversational software\n",
        "\n",
        "A short history\n",
        "- Conversational software is not a new idea!\n",
        "- Dates back to at least 1960s\n",
        "- First wave: command line applications\n",
        "- ELIZA: 1966\n",
        "\n",
        "\n",
        "Course content\n",
        "- Implementing smalltalk, ELIZA style\n",
        "- How to use regex and ML to extract meaning from free-form text\n",
        "- Build chatbots that can\n",
        "- Query a database\n",
        "- Plan a trip\n",
        "- Help you order coffee\n",
        "- Handling statefulness\n",
        "\n",
        "EchoBot I\n",
        "- In [1]: USER: Hello!\n",
        "- Out[1]: BOT: I can hear you, you said: 'Hello!'\n",
        "- In [2]: USER: How are you?\n",
        "- Out[2]: BOT: I can hear you, you said: 'How are you?'\n",
        "\n",
        "EchoBot II\n",
        "- In [1]: def respond(message):\n",
        "- : return \"I can hear you! you said: {}\".format(message)\n",
        "- In [2]: def send_message(message):\n",
        "- : # calls respond() to get response\n",
        "- In [3]: send_message(\"hello!\")\n",
        "- Out[3]: USER: hello!\n",
        "- ...: BOT : I can hear you! you said: hello!\n",
        "\n",
        "#### * EchoBot I\n",
        "\n",
        "Hello, World!\n",
        "\n",
        "You'll begin learning how to build chatbots in Python by writing two functions to build the simplest bot possible: EchoBot. EchoBot just responds by replying with the same message it receives.\n",
        "\n",
        "In this exercise, you'll define a function that responds to a user's message. In the next exercise, you'll complete EchoBot by writing a function to send a message to the bot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMBZo8MpielC",
        "colab_type": "code",
        "outputId": "cce55223-eb68-43ee-fd2d-65fa06b8a876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bot_template = \"BOT : {0}\"\n",
        "user_template = \"USER : {0}\"\n",
        "\n",
        "# Define a function that responds to a user's message: respond\n",
        "def respond(message):\n",
        "    # Concatenate the user's message to the end of a standard bot respone\n",
        "    bot_message = \"I can hear you! You said: \" + message\n",
        "    # Return the result\n",
        "    return bot_message\n",
        "\n",
        "# Test function\n",
        "print(respond(\"hello!\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I can hear you! You said: hello!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha-h2WcVotCh",
        "colab_type": "text"
      },
      "source": [
        "#### * EchoBot II\n",
        "Having written your respond() function, you'll now define a function called send_message() with a single parameter message which logs the message and the bot's response."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o7tvdFyolI_",
        "colab_type": "code",
        "outputId": "f7ad0452-a5f9-4ce7-f5b0-dc8b0ab22c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Create templates\n",
        "bot_template = \"BOT : {0}\"\n",
        "user_template = \"USER : {0}\"\n",
        "\n",
        "# Define a function that sends a message to the bot: send_message\n",
        "def send_message(message):\n",
        "    # Print user_template including the user_message\n",
        "    print(user_template.format(message))\n",
        "    # Get the bot's response to the message\n",
        "    response = respond(message)\n",
        "    # Print the bot template including the bot's response.\n",
        "    print(bot_template.format(response))\n",
        "\n",
        "# Send a message to the bot\n",
        "send_message(\"hello\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "USER : hello\n",
            "BOT : I can hear you! You said: hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UheTfr4O6q-g",
        "colab_type": "text"
      },
      "source": [
        "### Creating a personality\n",
        "\n",
        "Why personality?\n",
        "- Difference between a command line app and a chatbot\n",
        "- Makes chatbots and voice assistants more accessible and fun to use\n",
        "- Your users will expect it!\n",
        "\n",
        "#### Smalltalk\n",
        "    - In [1]: responses = {\n",
        "    - : \"what's your name?\": \"my name is EchoBot\",\n",
        "    - : \"what's the weather today?\": \"it's sunny!\"\n",
        "    - : }\n",
        "    - In [2]: def respond(message):\n",
        "    - : if message in responses:\n",
        "    - : return responses[message]\n",
        "    - In [3]: respond(\"what's your name?\")\n",
        "    - Out[3]: 'my name is EchoBot'\n",
        "    \n",
        "#### Including variables\n",
        "      - In [1]: responses = {\n",
        "      - : \"what's today's weather?\": \"it's {} today\"\n",
        "      - : }\n",
        "      - In [2]: weather_today = \"cloudy\"\n",
        "      - In [3]: def respond(message):\n",
        "      - : if message in responses:\n",
        "      - : return responses[message].format(weather_today)\n",
        "      - :\n",
        "      - In [4]: respond(\"what's today's weather?\")\n",
        "      - Out[4]: \"it's cloudy today\"\n",
        "      \n",
        "#### Choosing responses\n",
        "      - In [1]: responses = {\n",
        "      - : \"what's your name?\": [\n",
        "      - : \"my name is EchoBot\"\n",
        "      - ,\n",
        "      - : \"they call me EchoBot\"\n",
        "      - ,\n",
        "      - : \"the name's Bot, Echo Bot\"\n",
        "      - : ]\n",
        "      - : }\n",
        "      - In [2]: import random\n",
        "      - In [3]: def respond(message):\n",
        "      - : if message in responses:\n",
        "      - : return random.choice(responses[message])\n",
        "      - In [4]: respond(\"what's your name?\")\n",
        "      - Out[4]: \"the name's Bot, Echo Bot\"\n",
        "      \n",
        "#### Chitchat\n",
        "Now you're going to leave the simple EchoBot behind and create a bot which can answer simple questions such as \"What's your name?\" and \"What's today's weather?\"\n",
        "\n",
        "You'll use a dictionary with these questions as keys and the correct responses as values.\n",
        "\n",
        "This means the bot will only respond correctly if the message matches exactly, which is a big limitation. In later exercises you will create much more robust solutions.\n",
        "\n",
        "The send_message() function has already been defined for you, as well as the bot_template and user_template variables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esQxd7XjpLDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define variables\n",
        "name = \"Greg\"\n",
        "weather = \"cloudy\"\n",
        "\n",
        "# Define a dictionary with the predefined responses\n",
        "responses = {\n",
        "  \"what's your name?\": \"my name is {0}\".format(name),\n",
        "  \"what's today's weather?\": \"the weather is {0}\".format(weather),\n",
        "  \"default\": \"default message\"\n",
        "}\n",
        "\n",
        "# Return the matching response if there is one, default otherwise\n",
        "def respond(message):\n",
        "    # Check if the message is in the responses\n",
        "    if message in responses:\n",
        "        # Return the matching message\n",
        "        bot_message = responses[message]\n",
        "    else:\n",
        "        # Return the \"default\" message\n",
        "        bot_message = responses[\"default\"]\n",
        "    return bot_message\n",
        "  \n",
        "  \n",
        "  \n",
        "# Define variables\n",
        "name = \"Greg\"\n",
        "weather = \"cloudy\"\n",
        "\n",
        "# Define a dictionary with the predefined responses\n",
        "responses = {\n",
        "  \"what's your name?\": \"my name is {0}\".format(name),\n",
        "  \"what's today's weather?\": \"the weather is {0}\".format(weather),\n",
        "  \"default\": \"default message\"\n",
        "}\n",
        "\n",
        "# Return the matching response if there is one, default otherwise\n",
        "def respond(message):\n",
        "    # Check if the message is in the responses\n",
        "    if message in responses:\n",
        "        # Return the matching message\n",
        "        bot_message = responses[message]\n",
        "    else:\n",
        "        # Return the \"default\" message\n",
        "        bot_message = responses[\"default\"]\n",
        "    return bot_message"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VWWM-d3_QrC",
        "colab_type": "text"
      },
      "source": [
        "#### Adding variety\n",
        "It can get a little boring hearing the same old answers over and over. In this exercise, you'll add some variation. If you ask your bot how it's feeling, the likelihood that it responds with \"oh I'm great!\" or \"I'm very sad today\" should be equal.\n",
        "\n",
        "Here, you'll use the random module - specifically random.choice(ls) - which randomly selects an element from a list ls.\n",
        "\n",
        "A dictionary called responses, which maps each message to a list of possible responses, has been defined for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbL_aEbH-NUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the random module\n",
        "import random\n",
        "\n",
        "name = \"Greg\"\n",
        "weather = \"cloudy\"\n",
        "\n",
        "# Define a dictionary containing a list of responses for each message\n",
        "responses = {\n",
        "  \"what's your name?\": [\n",
        "      \"my name is {0}\".format(name),\n",
        "      \"they call me {0}\".format(name),\n",
        "      \"I go by {0}\".format(name)\n",
        "   ],\n",
        "  \"what's today's weather?\": [\n",
        "      \"the weather is {0}\".format(weather),\n",
        "      \"it's {0} today\".format(weather)\n",
        "    ],\n",
        "  \"default\": [\"default message\"]\n",
        "}\n",
        "\n",
        "# Use random.choice() to choose a matching response\n",
        "def respond(message):\n",
        "    # Check if the message is in the responses\n",
        "    if message in responses:\n",
        "        # Return a random matching response\n",
        "        bot_message = random.choice(responses[message])\n",
        "    else:\n",
        "        # Return a random \"default\" response\n",
        "        bot_message = random.choice(responses[\"default\"])\n",
        "    return bot_message\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhTwljmZS3tT",
        "colab_type": "code",
        "outputId": "bf20474b-f43c-43d8-a73e-a45ad32e743a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "res=[send_message(\"what's your name?\") for i in range(3)]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "USER : what's your name?\n",
            "BOT : I go by Greg\n",
            "USER : what's your name?\n",
            "BOT : my name is Greg\n",
            "USER : what's your name?\n",
            "BOT : my name is Greg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPrmt__cWTaK",
        "colab_type": "text"
      },
      "source": [
        "#### ELIZA I: asking questions\n",
        "Asking questions is a great way to create an engaging conversation. Here, you'll create the very first hint of ELIZA's famous personality, by responding to statements with a question and responding to questions with answers.\n",
        "\n",
        "A dictionary of responses with \"question\" and \"statement\" as keys and lists of appropriate responses as values has already been defined for you. Explore this in the Shell with responses.keys() and responses[\"question\"]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9Kt2_mBS75b",
        "colab_type": "code",
        "outputId": "e1907b72-a797-4849-c72a-16354811e92d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "responses={'question': [\"I don't know :(\", 'you tell me!'],\n",
        " 'statement': ['tell me more!',\n",
        "  'why do you think that?',\n",
        "  'how long have you felt this way?',\n",
        "  'I find that extremely interesting',\n",
        "  'can you back that up?',\n",
        "  'oh wow!',\n",
        "  ':)']}\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "def respond(message):\n",
        "    # Check for a question mark\n",
        "    if message.endswith(\"?\"):\n",
        "        # Return a random question\n",
        "        return random.choice(responses[\"question\"])\n",
        "    # Return a random statement\n",
        "    return random.choice(responses[\"statement\"])\n",
        "\n",
        "\n",
        "# Send messages ending in a question mark\n",
        "send_message(\"what's today's weather?\")\n",
        "send_message(\"what's today's weather?\")\n",
        "\n",
        "# Send messages which don't end with a question mark\n",
        "send_message(\"I love building chatbots\")\n",
        "send_message(\"I love building chatbots\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "USER : what's today's weather?\n",
            "BOT : you tell me!\n",
            "USER : what's today's weather?\n",
            "BOT : you tell me!\n",
            "USER : I love building chatbots\n",
            "BOT : oh wow!\n",
            "USER : I love building chatbots\n",
            "BOT : oh wow!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7fE7DfZx_Sl",
        "colab_type": "text"
      },
      "source": [
        "### Text processing with regular expressions\n",
        "\n",
        "Regular expressions\n",
        "- Match messages against known patterns\n",
        "- Extract key phrases\n",
        "- Transform sentences grammatically\n",
        "\n",
        "The regex behind ELIZA\n",
        "- USER: \"do you remember when you ate strawberries in the garden?\"\n",
        "- ELIZA: \"How could I forget when I ate strawberries in the garden?\"\n",
        "\n",
        "Pattern matching\n",
        "- In [1]: import re\n",
        "- In [2]: pattern = \"do you remember .*\"\n",
        "- In [3]: message = \"do you remember when you ate strawberries in the garden\"\n",
        "- In [4]: match = re.search(pattern, message)\n",
        "- In [5]: if match:\n",
        "- : print(\"string matches!\")\n",
        "- Out[5]: string matches!\n",
        "\n",
        "Extracting key phrases\n",
        "- In [1]: import re\n",
        "- In [2]: pattern = \"if (.*)\"\n",
        "- In [3]: message = \"what would happen if bots took over the world\"\n",
        "- In [4]: match = re.search(pattern, message)\n",
        "- In [5]: match.group(0)\n",
        "- Out[5]: 'what would happen if bots took over the world'\n",
        "- In [6]: match.group(1)\n",
        "- Out[6]: 'bots took over the world'\n",
        "\n",
        "Grammatical transformation\n",
        "- In [1]: import re\n",
        "- In [2]: def swap_pronouns(phrase):\n",
        "- ...: if 'I' in phrase:\n",
        "- ...:    return re.sub('I','you', phrase)\n",
        "- ...: if 'my' in phrase:\n",
        "- ...:    return re.sub('my','your', phrase)\n",
        "- ...: else:\n",
        "- ...:    return phrase\n",
        "- In [3]: swap_pronouns(\"I walk my dog\")\n",
        "- Out[3]: 'You walk your dog'\n",
        "\n",
        "Putting it all together\n",
        "- In [1]: pattern = 'do you remember (.*)'\n",
        "- In [2]: message = 'do you remember when you ate strawberries in the garden'\n",
        "- In [3]: phrase = pattern.search(pattern, message).group(1)\n",
        "- In [4]: phrase\n",
        "- Out[4]: 'when you ate strawberries in the garden'\n",
        "- In [5]: response = choose_response(pattern)\n",
        "- In [6]: response\n",
        "- Out[6]: 'how could I forget {}'\n",
        "- In [7]: phrase = swap_pronouns(phrase)\n",
        "- In [8]: phrase\n",
        "- Out[8]: 'when I ate strawberries in the garden'\n",
        "- In [9]: response.format(phrase)\n",
        "- Out[9]: 'how could I forget when I ate strawberries in the garden'\n",
        "\n",
        "\n",
        "#### ELIZA II: Extracting key phrases\n",
        "\n",
        "The really clever thing about ELIZA is the way the program appears to understand what you told it by occasionally including phrases uttered by the user in its responses.\n",
        "\n",
        "In this exercise, you will match messages against some common patterns and extract phrases using re.search(). A dictionary called rules has already been defined, which matches the following patterns:\n",
        "\n",
        "- \"do you think (.*)\"\n",
        "- \"do you remember (.*)\"\n",
        "- \"I want (.*)\"\n",
        "- \"if (.*)\"\n",
        "- Inspect this dictionary in the Shell before starting the exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kif2VZrdo7L1",
        "colab_type": "code",
        "outputId": "45bde04a-44fb-4f63-8c19-ff0cdf15d490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import re\n",
        "\n",
        "rules ={'I want (.*)': ['What would it mean if you got {0}',\n",
        "  'Why do you want {0}',\n",
        "  \"What's stopping you from getting {0}\"],\n",
        " 'do you remember (.*)': ['Did you think I would forget {0}',\n",
        "  \"Why haven't you been able to forget {0}\",\n",
        "  'What about {0}',\n",
        "  'Yes .. and?'],\n",
        " 'do you think (.*)': ['if {0}? Absolutely.', 'No chance'],\n",
        " 'if (.*)': [\"Do you really think it's likely that {0}\",\n",
        "  'Do you wish that {0}',\n",
        "  'What do you think about {0}',\n",
        "  'Really--if {0}']}\n",
        "\n",
        "\n",
        "# Define match_rule()\n",
        "def match_rule(rules, message):\n",
        "    response, phrase = \"default\", None\n",
        "    \n",
        "    # Iterate over the rules dictionary\n",
        "    for pattern, responses in rules.items():\n",
        "        # Create a match object\n",
        "        match = re.search(pattern,message)\n",
        "        if match is not None:\n",
        "            # Choose a random response\n",
        "            response = random.choice(responses)\n",
        "            if '{0}' in response:\n",
        "                phrase = match.group(1)\n",
        "    # Return the response and phrase\n",
        "    return response.format(phrase)\n",
        "\n",
        "# Test match_rule\n",
        "\n",
        "print(match_rule(rules, \"do you remember your last birthday\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Why haven't you been able to forget your last birthday\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj6C0JUZ0zNV",
        "colab_type": "text"
      },
      "source": [
        "### ELIZA III: Pronouns\n",
        "To make responses grammatically coherent, you'll want to transform the extracted phrases from first to second person and vice versa. In English, conjugating verbs is easy, and simply swapping \"me\" and 'you', \"my\" and \"your\" works in most cases.\n",
        "\n",
        "In this exercise, you'll define a function called replace_pronouns() which uses re.sub() to map \"me\" and \"my\" to \"you\" and \"your\" (and vice versa) in a string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SI_ug1P0aFU",
        "colab_type": "code",
        "outputId": "f4242d5c-e1f3-4cd9-98dd-22fbb667b40b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Define replace_pronouns()\n",
        "def replace_pronouns(message):\n",
        "  message = message.lower()\n",
        "  if 'me' in message:\n",
        "      # Replace 'me' with 'you'\n",
        "      return re.sub('me','you',message)\n",
        "  if 'my' in message:\n",
        "      # Replace 'my' with 'your'\n",
        "      return re.sub('my','your',message)\n",
        "  if 'your' in message:\n",
        "      # Replace 'your' with 'my'\n",
        "      return re.sub('your','my',message)\n",
        "  if 'you' in message:\n",
        "      # Replace 'you' with 'me'\n",
        "      return re.sub('you','me',message)\n",
        "\n",
        "  return message\n",
        "\n",
        "print(replace_pronouns(\"my last birthday\"))\n",
        "print(replace_pronouns(\"when you went to Florida\"))\n",
        "print(replace_pronouns(\"I had my own castle\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "your last birthday\n",
            "when me went to florida\n",
            "i had your own castle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5rL3epQ09O-",
        "colab_type": "text"
      },
      "source": [
        "### ELIZA IV: Putting it all together\n",
        "Now you're going to put everything from the previous exercises together and experience the magic! The match_rule(), send_message(), and replace_pronouns() functions have already been defined, and the rules dictionary is available in your workspace.\n",
        "\n",
        "Your job here is to write a function called respond() with a single argument message which creates an appropriate response to be handled by send_message()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EEVi3aJ04u7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define match_rule()\n",
        "def match_rule(rules, message):\n",
        "    response, phrase = \"default\", None\n",
        "    \n",
        "    # Iterate over the rules dictionary\n",
        "    for pattern, responses in rules.items():\n",
        "        # Create a match object\n",
        "        match = re.search(pattern,message)\n",
        "        if match is not None:\n",
        "            # Choose a random response\n",
        "            response = random.choice(responses)\n",
        "            if '{0}' in response:\n",
        "                phrase = match.group(1)\n",
        "    # Return the response and phrase\n",
        "    return response.format(phrase),phrase\n",
        "  \n",
        "  # Define replace_pronouns()\n",
        "def replace_pronouns(message):\n",
        "  message = message.lower()\n",
        "  if 'me' in message:\n",
        "      # Replace 'me' with 'you'\n",
        "      return re.sub('me','you',message)\n",
        "  if 'my' in message:\n",
        "      # Replace 'my' with 'your'\n",
        "      return re.sub('my','your',message)\n",
        "  if 'your' in message:\n",
        "      # Replace 'your' with 'my'\n",
        "      return re.sub('your','my',message)\n",
        "  if 'you' in message:\n",
        "      # Replace 'you' with 'me'\n",
        "      return re.sub('you','me',message)\n",
        "\n",
        "  return message\n",
        "\n",
        "\n",
        "# Define respond()\n",
        "def respond(message):\n",
        "    # Call match_rule\n",
        "    response, phrase = match_rule(rules,message)\n",
        "    if '{0}' in response:\n",
        "        # Replace the pronouns in the phrase\n",
        "        phrase = replace_pronouns(phrase)\n",
        "        # Include the phrase in the response\n",
        "        response = response.format(phrase)\n",
        "    return response\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWr6k3yR1Bs7",
        "colab_type": "code",
        "outputId": "dcc9f1d3-af4b-486b-9bf5-96bbd5a018e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Send the messages\n",
        "send_message(\"do you remember your last birthday\")\n",
        "send_message(\"do you think humans should be worried about AI\")\n",
        "send_message(\"I want a robot friend\")\n",
        "send_message(\"what if you could be anything you wanted\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "USER : do you remember your last birthday\n",
            "BOT : What about your last birthday\n",
            "USER : do you think humans should be worried about AI\n",
            "BOT : if humans should be worried about AI? Absolutely.\n",
            "USER : I want a robot friend\n",
            "BOT : What's stopping you from getting a robot friend\n",
            "USER : what if you could be anything you wanted\n",
            "BOT : Really--if you could be anything you wanted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz0CGLa4dYEg",
        "colab_type": "text"
      },
      "source": [
        "#### Understanding intents and entities\n",
        "\n",
        "#### Intents\n",
        " A restaurant_search can be expressed many different ways:\n",
        "- I'm hungry\n",
        "- Show me good pizza spots\n",
        "- I want to take my boyfriend out for sushi\n",
        "- Can also be request_booking\n",
        "\n",
        "#### Entities\n",
        "- NER = Named Entity Recognition\n",
        "- Ex : Book a table for *June 10th* at a *sushi* restaurent in *new york city*\n",
        "\n",
        "Regular expressions to recognize intents and entities\n",
        "- Simpler than machine learning approaches\n",
        "- Highly computationally efficient\n",
        "- Drawback:\n",
        "   - Debugging regular expressions can become difficult\n",
        "   \n",
        "   \n",
        "   \n",
        "#### Using regular expressions\n",
        "- '|' is equivalent to OR\n",
        "- \\b matches the beginning or end of a word\n",
        "\n",
        "\n",
        "   -   In [1]: re.search(r\"(hello|hey|hi)\",\"hey there!\") is not None\n",
        "   -   Out[1]: True\n",
        "   -   In [2]: re.search(r\"(hello|hey|hi)\",\"which one?\") is not None\n",
        "   -   Out[2]: True\n",
        "   -   In [3]: re.search(r\"\\b(hello|hey|hi)\\b\",\"hey there!\") is not None\n",
        "   -   Out[3]: True\n",
        "   -   In [4]: re.search(r\"\\b(hello|hey|hi)\\b\",\"which one?\") is not None\n",
        "   -   Out[4]: False\n",
        "   \n",
        "   \n",
        "#### Using regex for entity recognition\n",
        "- In [1]: pattern = re.compile('[A-Z]{1}[a-z]*')\n",
        "- In [2]: message = \"\"\"\n",
        "   Mary is a friend of mine,\n",
        "    she studied at Oxford and\n",
        "     now works at Google\"\"\"\n",
        "- In [3]: pattern.findall(message)\n",
        "- Out[3]: ['Mary','Oxford','Google']\n",
        "\n",
        "\n",
        "\n",
        "#### Intent classification with regex I\n",
        "\n",
        "\n",
        "You'll begin by implementing a very simple technique to recognize intents - looking for the presence of keywords.\n",
        "\n",
        "A dictionary, keywords, has already been defined. It has the intents \"greet\", \"goodbye\", and \"thankyou\" as keys, and lists of keywords as the corresponding values. For example, keywords[\"greet\"] is set to \"[\"hello\",\"hi\",\"hey\"].\n",
        "\n",
        "Also defined is a second dictionary, responses, indicating how the bot should respond to each of these intents. It also has a default response with the key \"default\".\n",
        "\n",
        "The function send_message(), along with the bot and user templates, have also already been defined. Your job in this exercise is to create a dictionary with the intents as keys and regex objects as values.\n",
        "\n",
        "\n",
        "instructions:\n",
        "\n",
        "- Iterate over the keywords dictionary, using intent and keys as your iterator variables.\n",
        "- Use '|'.join(keys) to create regular expressions to match at least one of the keywords and pass it to re.compile() to compile the regular expressions into pattern objects. Store the result as the value of the patterns dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiJy6-gA1qDE",
        "colab_type": "code",
        "outputId": "3b35961a-1696-4dfb-bcec-ff46611c8884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import re\n",
        "\n",
        "keywords={'thankyou': ['thank', 'thx'], 'greet': ['hello', 'hi', 'hey'], 'goodbye': ['bye', 'farewell']}\n",
        "\n",
        "responses ={'default': 'default message',\n",
        " 'goodbye': 'goodbye for now',\n",
        " 'greet': 'Hello you! :)',\n",
        " 'thankyou': 'you are very welcome'}\n",
        "\n",
        "\n",
        "# Define a dictionary of patterns\n",
        "patterns = {}\n",
        "\n",
        "# Iterate over the keywords dictionary\n",
        "for intent, keys in keywords.items():\n",
        "    # Create regular expressions and compile them into pattern objects\n",
        "    patterns[intent] = re.compile('|'.join(keys))\n",
        "    \n",
        "# Print the patterns\n",
        "print(patterns)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'thankyou': re.compile('thank|thx'), 'greet': re.compile('hello|hi|hey'), 'goodbye': re.compile('bye|farewell')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djp47PFx3lB1",
        "colab_type": "text"
      },
      "source": [
        "### Intent classification with regex II\n",
        "With your patterns dictionary created, it's now time to define a function to find the intent of a message.\n",
        "\n",
        "\n",
        "instructions:\n",
        "\n",
        "- Iterate over the intents and patterns in the patterns dictionary using its .items() method.\n",
        "- Use the .search() method of pattern to look for keywords in the message.\n",
        "If there is a match, return the corresponding intent.\n",
        "- Call your match_intent() function inside respond() with message as the argument and then hit 'Submit Answer' to see how the bot responds to the provided messages.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnsAfWvg7WgB",
        "colab_type": "code",
        "outputId": "641ab5cf-4e12-497b-999c-78f3996ee358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Define a function to find the intent of a message\n",
        "def match_intent(message):\n",
        "    matched_intent = None\n",
        "    for intent, pattern in patterns.items():\n",
        "        # Check if the pattern occurs in the message \n",
        "        if pattern.search(message ):\n",
        "            matched_intent = intent\n",
        "    return matched_intent\n",
        "\n",
        "# Define a respond function\n",
        "def respond(message):\n",
        "    # Call the match_intent function\n",
        "    intent = match_intent(message)\n",
        "    # Fall back to the default response\n",
        "    key = \"default\"\n",
        "    if intent in responses:\n",
        "        key = intent\n",
        "    return responses[key]\n",
        "  \n",
        "  \n",
        "# Create templates\n",
        "bot_template = \"BOT : {0}\"\n",
        "user_template = \"USER : {0}\"\n",
        "\n",
        "# Define a function that sends a message to the bot: send_message\n",
        "def send_message(message):\n",
        "    # Print user_template including the user_message\n",
        "    print(user_template.format(message))\n",
        "    # Get the bot's response to the message\n",
        "    response = respond(message)\n",
        "    # Print the bot template including the bot's response.\n",
        "    print(bot_template.format(response))\n",
        "\n",
        "# Send messages\n",
        "send_message(\"hello!\")\n",
        "send_message(\"bye byeee\")\n",
        "send_message(\"thanks very much!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "USER : hello!\n",
            "BOT : Hello you! :)\n",
            "USER : bye byeee\n",
            "BOT : goodbye for now\n",
            "USER : thanks very much!\n",
            "BOT : you are very welcome\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHrJEd-49CZM",
        "colab_type": "text"
      },
      "source": [
        "Entity extraction with regex\n",
        "Now you'll use another simple method, this time for finding a person's name in a sentence, such as \"hello, my name is David Copperfield\".\n",
        "\n",
        "You'll look for the keywords \"name\" or \"call(ed)\", and find capitalized words using regex and assume those are names. Your job in this exercise is to define a find_name() function to do this.\n",
        "\n",
        "instructions:\n",
        "\n",
        "- Use re.compile() to create a pattern for checking if \"name\" or \"call\" keywords occur.\n",
        "- Create a pattern for finding capitalized words.\n",
        "- Use the .findall() method on name_pattern to retrieve all matching words in message.\n",
        "- Call your find_name() function inside respond() and then hit 'Submit Answer' to see how the bot responds to the provided messages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-BYecir7fhW",
        "colab_type": "code",
        "outputId": "1d4e6a92-4f78-4bb8-d531-01e0059458e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Define find_name()\n",
        "def find_name(message):\n",
        "    name = None\n",
        "    # Create a pattern for checking if the keywords occur\n",
        "    name_keyword = re.compile('name|call')\n",
        "    # Create a pattern for finding capitalized words\n",
        "    name_pattern =  re.compile('[A-Z]{1}[a-z]*')\n",
        "    if name_keyword.search(message):\n",
        "        # Get the matching words in the string\n",
        "        name_words = name_pattern.findall(message)\n",
        "        if len(name_words) > 0:\n",
        "            # Return the name if the keywords are present\n",
        "            name = ' '.join(name_words)\n",
        "    return name\n",
        "\n",
        "# Define respond()\n",
        "def respond(message):\n",
        "    # Find the name\n",
        "    name = find_name(message)\n",
        "    if name is None:\n",
        "        return \"Hi there!\"\n",
        "    else:\n",
        "        return \"Hello, {0}!\".format(name)\n",
        "\n",
        "# Send messages\n",
        "send_message(\"my name is David Copperfield\")\n",
        "send_message(\"call me Ishmael\")\n",
        "send_message(\"People call me Cassandra\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "USER : my name is David Copperfield\n",
            "BOT : Hello, David Copperfield!\n",
            "USER : call me Ishmael\n",
            "BOT : Hello, Ishmael!\n",
            "USER : People call me Cassandra\n",
            "BOT : Hello, People Cassandra!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKYZSelDHEjb",
        "colab_type": "text"
      },
      "source": [
        "#### Word vectors\n",
        "\n",
        "Machine learning\n",
        "- Programs which can get better at a task by being exposed to more data\n",
        "- Identifying which intent a user message belongs to\n",
        "\n",
        "\n",
        "Word vectors\n",
        "* - Context        ===         Candidates\n",
        "* - let's meet at the ___ tomorrow === office, gym, park, beach, party\n",
        "*- I love going to the ___ to play with the dogs === beach, park\n",
        "\n",
        "\n",
        "- Word vectors try to represent meaning of words\n",
        "- Words which appear in similar context have similar vectors\n",
        "\n",
        "Word vectors are computationally intensive\n",
        "- Training word vectors requires a lot of data\n",
        "- High quality word vectors are available for anyone to use\n",
        "- GloVe algorithm\n",
        "     - Cousin of word2vec\n",
        "- spaCy\n",
        "\n",
        "\n",
        "### DataCamp Building Chatbots in Python\n",
        "- Word vectors in spaCy\n",
        "    - In [1]: import spacy\n",
        "    - In [2]: nlp = spacy.load('en')\n",
        "    - In [3]: nlp.vocab.vectors_length\n",
        "    - Out[3]: 300\n",
        "    - In [4]: doc = nlp('hello can you help me?')\n",
        "    - In [5]: for token in doc:\\\n",
        "...: print(\"{} : {}\".format(token, token.vector[:3]))\n",
        "\n",
        "\n",
        "hello : [ 0.25233001 0.10176 -0.67484999]\n",
        "\n",
        "can : [-0.23857 0.35457 -0.30219001] \\\n",
        "you : [-0.11076 0.30785999 -0.51980001]\\\n",
        "help : [-0.29370001 0.32253 -0.44779 ]\\\n",
        "me : [-0.15396 0.31894001 -0.54887998]\\\n",
        "? : [-0.086864 0.19160999 0.10915 ]\n",
        "\n",
        "#### Similarity\n",
        "\n",
        "\n",
        "- Direction of vectors matters\n",
        "- \"Distance\" between words = angle between the vectors\n",
        "- Cosine similarity\n",
        "     - 1: If vectors point in the same direction\n",
        "     - 0: If they are perpendicular\n",
        "     - -1: If they point in opposite directions\n",
        "     \n",
        "#### .similarity()\n",
        "\n",
        "- \"can\" and \"cat\" are spelled similarly but have low similarity\n",
        "- but \"cat\" and \"dog\" have high similarity\n",
        "- In [1]: import spacy\n",
        "- In [2]: nlp = spacy.load('en')\n",
        "- In [3]: doc = nlp(\"cat\")\n",
        "- In [4]: doc.similarity(nlp(\"can\"))\\\n",
        "Out[4]: 0.30165292161215396\n",
        "- In [5]: doc.similarity(nlp(\"dog\"))\\\n",
        " Out[5]: 0.80168555173294953"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG1MFO5wSV0A",
        "colab_type": "text"
      },
      "source": [
        "#### word vectors with spaCy\n",
        "In this exercise you'll get your first experience with word vectors! You're going to use the ATIS dataset, which contains thousands of sentences from real people interacting with a flight booking system.\n",
        "\n",
        "The user utterances are available in the list sentences, and the corresponding intents in labels.\n",
        "\n",
        "Your job is to create a 2D array X with as many rows as there are sentences in the dataset, where each row is a vector describing that sentence.\n",
        "\n",
        "- Load the spaCy English model by calling spacy.load() with argument 'en'.\n",
        "- Calculate the length of sentences using len() and the dimensionality of the word vectors using nlp.vocab.vectors_length.\n",
        "- For each sentence, call the nlp object with the sentence as the sole argument. Store the result as doc.\n",
        "- Use the .vector attribute of doc to get the vector representation of each sentence, and store this vector in the appropriate row of X."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_NDq7wKiDmr",
        "colab_type": "code",
        "outputId": "946ad880-8588-45aa-8216-9b12f86c38a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!pip install -U spacy\n",
        "\n",
        "#pip install -U spacy[cuda92] for GPU suport"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy in /usr/local/lib/python3.6/dist-packages (2.2.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.16.5)\n",
            "Requirement already satisfied, skipping upgrade: thinc<7.2.0,>=7.1.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.1.1)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.2.0,>=7.1.1->spacy) (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Pa9DIdZjslT",
        "colab_type": "code",
        "outputId": "be8c80ed-8dc1-43d2-de64-8e5e28c45b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "!python -m spacy download en_core_web_lg\n",
        "\n",
        "# after installing the  packges in the colb you shuld restart the runtime "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz#egg=en_core_web_lg==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
            "\u001b[K     |████████████████████████████████| 826.9MB 1.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255076 sha256=44e91232b50f8bccd889062caeed407ee890b1cadfe2a87341b21e4c03e1d971\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sevyc9g1/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXUCZThW-Q7H",
        "colab_type": "code",
        "outputId": "2eb86f52-3354-41ad-add9-5aea76d06b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sentences= [' i want to fly from boston at 838 am and arrive in denver at 1110 in the morning',\n",
        " ' what flights are available from pittsburgh to baltimore on thursday morning',\n",
        " ' what is the arrival time in san francisco for the 755 am flight leaving washington',\n",
        " ' cheapest airfare from tacoma to orlando',\n",
        " ' round trip fares from pittsburgh to philadelphia under 1000 dollars',\n",
        " ' i need a flight tomorrow from columbus to minneapolis',\n",
        " ' what kind of aircraft is used on a flight from cleveland to dallas',\n",
        " ' show me the flights from pittsburgh to los angeles on thursday',\n",
        " ' all flights from boston to washington',\n",
        " ' what kind of ground transportation is available in denver',\n",
        " ' show me the flights from dallas to san francisco',\n",
        " ' show me the flights from san diego to newark by way of houston',\n",
        " ' what is the cheapest flight from boston to bwi',\n",
        " ' all flights to baltimore after 6 pm',\n",
        " ' show me the first class fares from boston to denver',\n",
        " ' show me the ground transportation in denver',\n",
        " ' all flights from denver to pittsburgh leaving after 6 pm and before 7 pm',\n",
        " ' i need information on flights for tuesday leaving baltimore for dallas dallas to boston and boston to baltimore',\n",
        " ' please give me the flights from boston to pittsburgh on thursday of next week',\n",
        " ' i would like to fly from denver to pittsburgh on united airlines',\n",
        " ' show me the flights from san diego to newark',\n",
        " ' please list all first class flights on united from denver to baltimore',\n",
        " ' what kinds of planes are used by american airlines',\n",
        " \" i'd like to have some information on a ticket from denver to pittsburgh and atlanta\",\n",
        " \" i'd like to book a flight from atlanta to denver\",\n",
        " ' which airline serves denver pittsburgh and atlanta',\n",
        " \" show me all flights from boston to pittsburgh on wednesday of next week which leave boston after 2 o'clock pm\",\n",
        " ' atlanta ground transportation',\n",
        " ' i also need service from dallas to boston arriving by noon',\n",
        " ' show me the cheapest round trip fare from baltimore to dallas']\n",
        "\n",
        "\n",
        "print(len(sentences))\n",
        "\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load the spacy model: nlp\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "\n",
        "# Calculate the length of sentences\n",
        "n_sentences = len(sentences)\n",
        "\n",
        "# Calculate the dimensionality of nlp\n",
        "embedding_dim =  nlp.vocab.vectors_length\n",
        "\n",
        "# Initialize the array with zeros: X\n",
        "X = np.zeros((n_sentences,embedding_dim ))\n",
        "\n",
        "print( embedding_dim)\n",
        "print(X.shape)\n",
        "\n",
        "\n",
        "# Iterate over the sentences\n",
        "for idx, sentence in enumerate(sentences):\n",
        "    # Pass each each sentence to the nlp object to create a document\n",
        "    doc = nlp(sentence)\n",
        "    # Save the document's .vector attribute to the corresponding row in X\n",
        "    X[idx, :] = doc.vector\n",
        "    \n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "300\n",
            "(30, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDJEQa5qjXSF",
        "colab_type": "code",
        "outputId": "0216755a-20cb-40d8-a896-ea8418c38478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!python -m spacy validate\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r⠙ Loading compatibility table...\r\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
            "\u001b[1m\n",
            "====================== Installed models (spaCy v2.1.8) ======================\u001b[0m\n",
            "\u001b[38;5;4mℹ spaCy installation: /usr/local/lib/python3.6/dist-packages/spacy\u001b[0m\n",
            "\n",
            "TYPE      NAME             MODEL            VERSION                            \n",
            "package   en-core-web-sm   en_core_web_sm   \u001b[38;5;2m2.1.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "package   en-core-web-lg   en_core_web_lg   \u001b[38;5;2m2.1.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "link      en               en_core_web_sm   \u001b[38;5;2m2.1.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6OOwtjzq7zP",
        "colab_type": "text"
      },
      "source": [
        "### Intents and classification\n",
        "\n",
        "Supervised learning\n",
        "- A classifier predicts the intent label given a sentence\n",
        "- 'Fit' classifier by tuning it on training data\n",
        "- Evaluate performance on test data\n",
        "- Accuracy: the fraction of labels we predict correctly\n",
        "\n",
        "ATIS dataset\n",
        "- Thousands of sentences with labeled intents and entities\n",
        "- Collected from a real flight booking service\n",
        "- Intents like\n",
        "- atis_flight\n",
        "- atis_airfare\n",
        "- DataCamp Building Chatbots in Python\n",
        "\n",
        "\n",
        "ATIS dataset II\n",
        "- In [1]: sentences_train[:2]\n",
        "- Out[1]: [\n",
        "      \"i want to fly from boston at 838 am and arrive in denver at 1110 in the morning\" ,\"what flights are available from pittsburgh to baltimore on thursday morning\" ]\n",
        "- In [2]: labels_train[:2]\n",
        "- Out[2]: [\n",
        " \"atis_flight\"\n",
        " ,\n",
        " \"atis_flight\"\n",
        "]\n",
        "- In [3]: import numpy as np\n",
        "- In [4]: X_train_shape = (len(sentences_train),nlp.vocab.vectors_length)\n",
        "- In [5]: X_train = np.zeros(X_train_shape)\n",
        "- In [6]: for sentence in sentences_train:\n",
        "...: X_train[i,:] = nlp(sentence).vector\n",
        "\n",
        "\n",
        "Nearest neighbor classification\n",
        "- Need training data\n",
        "- Sentences which we've already labeled with their intents\n",
        "- Simplest solution:\n",
        "- Look for the labeled example that's most similar\n",
        "- Use its intent as a best guess\n",
        "- Nearest neighbor classification\n",
        "\n",
        "\n",
        "Nearest neighbor classification in scikit-learn\n",
        "- In [1]: from sklearn.metrics.pairwise import cosine_similarity\n",
        "- In [2]: test_message = \"\"\"\n",
        "- i would like to find a flight from charlotte\n",
        "- to las vegas that makes a stop in st. louis\"\"\"\n",
        "- In [3]: test_x = nlp(test_message).vector\n",
        "- In [4]: scores = [\\\n",
        " ...: cosine_similarity(X[i,:], test_x) \\\n",
        "...: for i in range(len(sentences_train)\\\n",
        " ...: ]\n",
        "- In [5]: labels_train[np.argmax(scores)]\n",
        "- Out[5]: 'atis_flight'\n",
        "\n",
        "\n",
        "Support vector machines\n",
        "- Nearest neighbours is very simple - we can do better\n",
        "- SVM / SVC: support vector machine / classifier\n",
        "- In [1]: from sklearn.svm import SVC\n",
        "- In [2]: clf = SVC()\n",
        "- In [3]: clf.fit(X_train, y_train)\n",
        "- In [4]: y_pred = clf.predict(X_test)\n",
        "\n",
        "### Intent classification with sklearn\n",
        "An array X containing vectors describing each of the sentences in the ATIS dataset has been created for you, along with a 1D array y containing the labels. The labels are integers corresponding to the intents in the dataset. For example, label 0 corresponds to the intent atis_flight.\n",
        "\n",
        "Now, you'll use the scikit-learn library to train a classifier on this same dataset. Specifically, you will fit and evaluate a support vector classifier.\n",
        "\n",
        "\n",
        "instructions:\n",
        "\n",
        "Import the SVC class from sklearn.svm.\n",
        "- Instantiate a classifier clf by calling SVC with a single keyword argument C with value 1.\n",
        "- Fit the classifier to the training data X_train and y_train.\n",
        "Predict the labels of the test set, X_test.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2X9xvP2v1B_",
        "colab_type": "code",
        "outputId": "8677a5c6-1cd0-435e-fc1d-544ec71a60c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Import label encoder \n",
        "from sklearn import preprocessing \n",
        "\n",
        "\n",
        "# label_encoder object knows how to understand word labels. \n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "\n",
        "\n",
        "df1 =pd.read_csv('atis_intents_train.csv',header=None,  names=['lbl0', 'text'])\n",
        "#df.head()\n",
        "\n",
        "\n",
        "df2 =pd.read_csv('atis_intents_test.csv',header=None,  names=['lbl0', 'text'])\n",
        "#df.head()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(df1['lbl0'].unique() )\n",
        "\n",
        "# Encode labels in column 'lbl0'. \n",
        "df1['lbl0']= label_encoder.fit_transform(df1['lbl0']) \n",
        "\n",
        "# Encode labels in column 'species'. \n",
        "df2['lbl0']= label_encoder.fit_transform(df2['lbl0']) \n",
        "\n",
        "print(df1['lbl0'].unique() ) \n",
        "\n",
        "\n",
        "\n",
        "X_train= df1[\"text\"]\n",
        "X_train.head()\n",
        "\n",
        "y_train = df1['lbl0']\n",
        "\n",
        "\n",
        "X_test= df2[\"text\"]\n",
        "print(X_test.head())\n",
        "\n",
        "y_test = df2['lbl0']\n",
        "print(y_test.head())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['atis_flight' 'atis_flight_time' 'atis_airfare' 'atis_aircraft'\n",
            " 'atis_ground_service' 'atis_airline' 'atis_abbreviation' 'atis_quantity']\n",
            "[4 5 2 1 6 3 0 7]\n",
            "0     i would like to find a flight from charlotte ...\n",
            "1     on april first i need a ticket from tacoma to...\n",
            "2     on april first i need a flight going from pho...\n",
            "3     i would like a flight traveling one way from ...\n",
            "4     i would like a flight from orlando to salt la...\n",
            "Name: text, dtype: object\n",
            "0    4\n",
            "1    2\n",
            "2    4\n",
            "3    4\n",
            "4    4\n",
            "Name: lbl0, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxZl2NhRko_z",
        "colab_type": "code",
        "outputId": "8e3012d0-59e9-4824-f576-c5cf147ef5a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "# Import SVC\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create a support vector classifier\n",
        "clf = SVC(C=1)\n",
        "\n",
        "# Fit the classifier using the training data\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Count the number of correct predictions\n",
        "n_correct = 0\n",
        "for i in range(len(y_test)):\n",
        "    if y_pred[i] == y_test[i]:\n",
        "        n_correct += 1\n",
        "\n",
        "print(\"Predicted {0} correctly out of {1} test examples\".format(n_correct, len(y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-550dc368c4d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Fit the classifier using the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Predict the labels of the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    144\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[1;32m    145\u001b[0m                          \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'M8[ns]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/arrays/numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ' i want to fly from boston at 838 am and arrive in denver at 1110 in the morning'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UwFI010UfFu",
        "colab_type": "text"
      },
      "source": [
        "## Entity extraction\n",
        "\n",
        "### Beyond keywords: Context\n",
        "\n",
        "- Keywords don't work for entities you haven't seen before\n",
        "- Use contextual clues:\n",
        "  - Spelling\n",
        "  - Capitalization\n",
        "  - Words occurring before & after\n",
        "- Pattern recognition\n",
        "\n",
        "\n",
        "### Pre-built Named Entity Recognition\n",
        "- In [1]: import spacy\n",
        "- In [2]: nlp = spacy.load('en')\n",
        "- In [3]: doc = nlp(\"my friend Mary has worked at Google since 2009\")\n",
        "- In [4]: for ent in doc.ents:\\ \n",
        "\n",
        "  ...: print(ent.text, ent.label_)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cdNVvSRvqVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}